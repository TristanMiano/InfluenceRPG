#!/usr/bin/env python3
"""
gm_llm.py - Module for Game Master LLM functionality

This module provides a function for generating narrative responses in a game chat.
It leverages the generic LLM client (from src/llm/llm_client.py) and is designed to handle
the full conversation context that occurs during a chat session.

Usage:
    Call generate_gm_response(conversation_context, trigger_prompt) to produce a GM narrative response.
"""

from src.llm.llm_client import generate_completion
from src.utils.prompt_loader import load_prompt_template

def generate_gm_response(conversation_context: str, trigger_prompt: str = "Provide a narrative update.") -> str:
    """
    Generate a narrative GM response based on the full conversation context and an optional trigger prompt.
    
    Args:
        conversation_context (str): The full conversation history for context.
        trigger_prompt (str, optional): A specific prompt to guide the GM's response.
                                        Defaults to "Provide a narrative update."
    
    Returns:
        str: A narrative response generated by the GM.
    """
    # Construct a specialized prompt for the GM using a template.
    template = load_prompt_template("gm_llm_system.txt")
    gm_prompt = template.format(
        conversation_context=conversation_context,
        trigger_prompt=trigger_prompt,
    )
    # Use the generic LLM client to generate the completion.
    # Note: The conversation context is already embedded into the prompt.
    response = generate_completion(prompt=gm_prompt, conversation_context="")
    return response

if __name__ == "__main__":
    # Test block to verify GM LLM functionality.
    sample_context = (
        "User1: Our defenses are weak; we might need reinforcements.\n"
        "User2: Agreed. Perhaps we can use the hidden passage to flank the enemy.\n"
        "User1: The enemy is advancing fast, and time is short!"
    )
    test_trigger = "What is our next move?"
    gm_response = generate_gm_response(sample_context, trigger_prompt=test_trigger)
    print("GM LLM Response:")
    print(gm_response)
