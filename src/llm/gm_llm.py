#!/usr/bin/env python3
"""
gm_llm.py - Module for Game Master LLM functionality

This module provides a function for generating narrative responses in a game chat.
It leverages the generic LLM client (from src/llm/llm_client.py) and is designed to handle
the full conversation context that occurs during a chat session.

Usage:
    Call generate_gm_response(conversation_context, trigger_prompt) to produce a GM narrative response.
"""

from typing import Any, Dict, Tuple
import json

from src.llm.llm_client import generate_completion
from src.utils.prompt_loader import load_prompt_template


def generate_gm_output(
    conversation_context: str,
    trigger_prompt: str = "Provide a narrative update.",
    entity_list: str = "",
) -> Tuple[str, Dict[str, Any]]:
    """Generate a GM response along with any desired tool calls."""
    template = load_prompt_template("gm_llm_system.txt")
    gm_prompt = template.format(
        conversation_context=conversation_context,
        trigger_prompt=trigger_prompt,
        entity_list=entity_list,
    )
    raw = generate_completion(prompt=gm_prompt, conversation_context="")
    try:
        data = json.loads(raw.strip())
        text = data.get("narrative", "")
        tools = data.get("tool_calls", {}) if isinstance(data.get("tool_calls"), dict) else {}
        return text, tools
    except Exception:
        # If parsing fails, treat entire output as narrative only
        return raw.strip(), {}

def generate_gm_response(
    conversation_context: str,
    trigger_prompt: str = "Provide a narrative update.",
    entity_list: str = "",
) -> str:
    """
    Generate a narrative GM response based on the full conversation context and an optional trigger prompt.
    
    Args:
        conversation_context (str): The full conversation history for context.
        trigger_prompt (str, optional): A specific prompt to guide the GM's response.
                                        Defaults to "Provide a narrative update."
        entity_list (str, optional): JSON string describing known entities to include in the prompt.
                                     Defaults to "".
    
    Returns:
        str: A narrative response generated by the GM.
    """
    text, _ = generate_gm_output(
        conversation_context=conversation_context,
        trigger_prompt=trigger_prompt,
        entity_list=entity_list,
    )
    return text

if __name__ == "__main__":
    # Test block to verify GM LLM functionality.
    sample_context = (
        "User1: Our defenses are weak; we might need reinforcements.\n"
        "User2: Agreed. Perhaps we can use the hidden passage to flank the enemy.\n"
        "User1: The enemy is advancing fast, and time is short!"
    )
    test_trigger = "What is our next move?"
    gm_response = generate_gm_response(sample_context, trigger_prompt=test_trigger, entity_list="[]")
    print("GM LLM Response:")
    print(gm_response)
